{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e270f53-2934-4793-a333-2febb7bdd9ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BASIC VALIDATION (quick) ===\n",
      "Shape (N, T, C): (180, 1000, 3)\n",
      "System class counts: [30 30 30 30 30 30]\n",
      "Sensor fault counts: [153   5   4   8  10]\n",
      "O2 in [0,100]: True\n",
      "CO2 in [0,5]:   True\n",
      "P in [0,20]:    True\n",
      "Class 0 (Nominal): mean O2=20.908, CO2=0.301, P=14.697\n",
      "Class 1 (CO2_Leak): mean O2=20.901, CO2=0.356, P=14.708\n",
      "Class 2 (Valve_Stiction): mean O2=20.901, CO2=0.305, P=14.702\n",
      "Class 3 (Vacuum_Anomaly): mean O2=20.902, CO2=0.300, P=14.635\n",
      "Class 4 (CDRA_Degradation): mean O2=20.901, CO2=0.571, P=14.700\n",
      "Class 5 (OGA_Degradation): mean O2=18.693, CO2=0.302, P=14.695\n",
      "\n",
      "Saved dataset to: C:\\Users\\ahasa\\data\\eclss_synthetic_dataset_full\n",
      "\n",
      "============================================================\n",
      "COMPREHENSIVE VALIDATION\n",
      "============================================================\n",
      "\n",
      "1. Physical Constraints:\n",
      "   O2 in [0.0, 100.0]: ✅\n",
      "   CO2 in [0.0, 5.0]: ✅\n",
      "   P in [0.0, 20.0]:   ✅\n",
      "\n",
      "2. Invalid Values:\n",
      "   No NaN: ✅\n",
      "   No Inf: ✅\n",
      "\n",
      "3. Temporal Coherence:\n",
      "   Mean lag-1 autocorr: 0.890 ✅\n",
      "\n",
      "4. Class Separability (PCA + silhouette):\n",
      "   Silhouette score (2D PCA): 0.209 ✅\n",
      "\n",
      "============================================================\n",
      "OVERALL PHYSICAL/NUMERIC: ✅ PASS\n",
      "============================================================\n",
      "\n",
      "✅ Visual validation saved: C:\\Users\\ahasa\\data\\eclss_synthetic_dataset_full\\dataset_validation_overlay.png\n",
      "✅ Summary report saved: C:\\Users\\ahasa\\data\\eclss_synthetic_dataset_full\\dataset_summary.md\n",
      "\n",
      "✅ Dataset generation, validation, plots, and summary complete.\n",
      "   Ready for VAE/SVM training.\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, \"en_US.UTF-8\")\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTHONIOENCODING\"] = \"utf-8\"\n",
    "os.environ[\"LC_ALL\"] = \"en_US.UTF-8\"\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Robust repo root detection\n",
    "try:\n",
    "    # Running as a script\n",
    "    REPO_ROOT = Path(__file__).resolve().parents[1]\n",
    "except NameError:\n",
    "    # Running in Colab or notebook\n",
    "    REPO_ROOT = Path.cwd()\n",
    "\n",
    "DEFAULT_DATA_DIR = REPO_ROOT / \"data\" / \"eclss_synthetic_dataset_full\"\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================\n",
    "\n",
    "@dataclass\n",
    "class DatasetConfig:\n",
    "    # Size\n",
    "    n_samples_per_system_class: int = 30\n",
    "    n_timesteps: int = 1000\n",
    "    sampling_rate_hz: float = 2.0\n",
    "\n",
    "    # Nominal values (ISS-aligned)\n",
    "    O2_nominal: float = 20.9          # %\n",
    "    CO2_nominal: float = 0.3          # % (~2 mmHg target)\n",
    "    pressure_nominal_psi: float = 14.7\n",
    "\n",
    "    # Nominal waveform amplitudes\n",
    "    O2_amp: float = 0.3\n",
    "    CO2_amp: float = 0.10\n",
    "    P_amp: float = 0.3\n",
    "\n",
    "    # Sensor noise\n",
    "    O2_noise_std: float = 0.05\n",
    "    CO2_noise_std: float = 0.02\n",
    "    P_noise_std: float = 0.05\n",
    "\n",
    "    # Slow drift (sensor aging / slow process drift)\n",
    "    enable_drift: bool = True\n",
    "    drift_std_O2: float = 0.01\n",
    "    drift_std_CO2: float = 0.003\n",
    "    drift_std_P: float = 0.01\n",
    "\n",
    "    # Cycle timing jitter\n",
    "    freq_jitter_range: Tuple[float, float] = (0.95, 1.05)\n",
    "\n",
    "    # System fault severity ranges\n",
    "    co2_leak_magnitude_range: Tuple[float, float] = (0.05, 0.40)\n",
    "    valve_stiction_alpha_range: Tuple[float, float] = (0.85, 0.99)\n",
    "    vacuum_drop_range: Tuple[float, float] = (0.5, 2.0)\n",
    "    cdra_offset_range: Tuple[float, float] = (0.05, 0.5)\n",
    "    oga_offset_range: Tuple[float, float] = (0.5, 4.0)\n",
    "\n",
    "    # Sensor faults\n",
    "    enable_sensor_faults: bool = True\n",
    "    p_sensor_fault: float = 0.15  # 15% of cycles get a sensor fault\n",
    "\n",
    "    # Sensor fault parameters\n",
    "    bias_drift_max: float = 0.5\n",
    "    high_noise_factor: float = 4.0\n",
    "    freeze_min_fraction: float = 0.2\n",
    "    freeze_max_fraction: float = 0.6\n",
    "    n_spikes_min: int = 5\n",
    "    n_spikes_max: int = 30\n",
    "    spike_magnitude_range: Tuple[float, float] = (0.5, 3.0)\n",
    "\n",
    "    # Physical limits (sanity clips)\n",
    "    O2_min: float = 0.0\n",
    "    O2_max: float = 100.0\n",
    "    CO2_min: float = 0.0\n",
    "    CO2_max: float = 5.0       # allow up to 5% for severe faults\n",
    "    P_min: float = 0.0\n",
    "    P_max: float = 20.0\n",
    "\n",
    "    # NASA-inspired health thresholds (for flags only)\n",
    "    CO2_warn: float = 0.7\n",
    "    CO2_crit: float = 1.0\n",
    "    O2_warn_low: float = 19.0   # closer to 20.9 nominal\n",
    "    O2_crit_low: float = 16.0\n",
    "    P_warn_low: float = 14.0\n",
    "    P_warn_high: float = 15.4\n",
    "    P_crit_low: float = 13.5\n",
    "    P_crit_high: float = 15.8\n",
    "\n",
    "    # Random seed\n",
    "    random_seed: int = 42\n",
    "\n",
    "\n",
    "# System modes (system-level faults)\n",
    "SYSTEM_CLASSES = [\n",
    "    (0, \"Nominal\"),\n",
    "    (1, \"CO2_Leak\"),\n",
    "    (2, \"Valve_Stiction\"),\n",
    "    (3, \"Vacuum_Anomaly\"),\n",
    "    (4, \"CDRA_Degradation\"),\n",
    "    (5, \"OGA_Degradation\"),\n",
    "]\n",
    "\n",
    "# Sensor fault types\n",
    "SENSOR_FAULTS = [\n",
    "    (0, \"None\"),\n",
    "    (1, \"Bias_Drift\"),\n",
    "    (2, \"High_Noise\"),\n",
    "    (3, \"Partial_Freeze\"),\n",
    "    (4, \"Spike_Outliers\"),\n",
    "]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# BASELINE NOMINAL GENERATION\n",
    "# ============================================================\n",
    "\n",
    "def generate_nominal_cycle(cfg: DatasetConfig,\n",
    "                           rng: np.random.Generator) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate one nominal adsorption–desorption cycle.\n",
    "    Returns array of shape (T, 3) with columns [O2, CO2, P].\n",
    "    \"\"\"\n",
    "    T = cfg.n_timesteps\n",
    "    t = np.linspace(0.0, 1.0, T)\n",
    "\n",
    "    # Small random frequency jitter\n",
    "    freq_scale = rng.uniform(*cfg.freq_jitter_range)\n",
    "\n",
    "    # Periodic behavior\n",
    "    O2 = cfg.O2_nominal + cfg.O2_amp * np.sin(2 * np.pi * freq_scale * t)\n",
    "    CO2 = cfg.CO2_nominal - cfg.CO2_amp * np.sin(2 * np.pi * freq_scale * t)\n",
    "    P = cfg.pressure_nominal_psi + cfg.P_amp * np.cos(2 * np.pi * freq_scale * t)\n",
    "\n",
    "    # Slow drift (random walk)\n",
    "    if cfg.enable_drift:\n",
    "        O2 += np.cumsum(rng.normal(0.0, cfg.drift_std_O2, T)) / T\n",
    "        CO2 += np.cumsum(rng.normal(0.0, cfg.drift_std_CO2, T)) / T\n",
    "        P += np.cumsum(rng.normal(0.0, cfg.drift_std_P, T)) / T\n",
    "\n",
    "    # Sensor noise\n",
    "    O2 += rng.normal(0.0, cfg.O2_noise_std, T)\n",
    "    CO2 += rng.normal(0.0, cfg.CO2_noise_std, T)\n",
    "    P += rng.normal(0.0, cfg.P_noise_std, T)\n",
    "\n",
    "    # Physical clipping\n",
    "    O2 = np.clip(O2, cfg.O2_min, cfg.O2_max)\n",
    "    CO2 = np.clip(CO2, cfg.CO2_min, cfg.CO2_max)\n",
    "    P = np.clip(P, cfg.P_min, cfg.P_max)\n",
    "\n",
    "    return np.stack([O2, CO2, P], axis=1)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# SYSTEM FAULT MODELS\n",
    "# ============================================================\n",
    "\n",
    "def _interp_from_severity(severity: float, low: float, high: float) -> float:\n",
    "    s = float(np.clip(severity, 0.0, 1.0))\n",
    "    return low + s * (high - low)\n",
    "\n",
    "\n",
    "def inject_co2_leak(cycle: np.ndarray, cfg: DatasetConfig,\n",
    "                    rng: np.random.Generator, severity: float) -> np.ndarray:\n",
    "    \"\"\"CO₂ leak: gradual elevation of CO₂ after mid-cycle.\"\"\"\n",
    "    faulty = cycle.copy()\n",
    "    T = faulty.shape[0]\n",
    "    mid = T // 2\n",
    "\n",
    "    mag = _interp_from_severity(severity, *cfg.co2_leak_magnitude_range)\n",
    "    ramp = np.linspace(0.0, mag, T - mid)\n",
    "    faulty[mid:, 1] += ramp\n",
    "\n",
    "    faulty[:, 1] = np.clip(faulty[:, 1], cfg.CO2_min, cfg.CO2_max)\n",
    "    return faulty\n",
    "\n",
    "\n",
    "def _lowpass_first_order(x: np.ndarray, alpha: float) -> np.ndarray:\n",
    "    \"\"\"First-order IIR low-pass filter.\"\"\"\n",
    "    y = np.empty_like(x)\n",
    "    y[0] = x[0]\n",
    "    for t in range(1, len(x)):\n",
    "        y[t] = alpha * y[t - 1] + (1.0 - alpha) * x[t]\n",
    "    return y\n",
    "\n",
    "\n",
    "def inject_valve_stiction(cycle: np.ndarray, cfg: DatasetConfig,\n",
    "                          rng: np.random.Generator, severity: float) -> np.ndarray:\n",
    "    \"\"\"Valve stiction: slower pressure dynamics via low-pass filtering.\"\"\"\n",
    "    faulty = cycle.copy()\n",
    "    alpha = _interp_from_severity(severity, *cfg.valve_stiction_alpha_range)\n",
    "    P = faulty[:, 2]\n",
    "    P_slow = _lowpass_first_order(P, alpha)\n",
    "    faulty[:, 2] = np.clip(P_slow, cfg.P_min, cfg.P_max)\n",
    "    return faulty\n",
    "\n",
    "\n",
    "def inject_vacuum_anomaly(cycle: np.ndarray, cfg: DatasetConfig,\n",
    "                          rng: np.random.Generator, severity: float) -> np.ndarray:\n",
    "    \"\"\"Vacuum anomaly: localized Gaussian-shaped pressure drop near mid-cycle.\"\"\"\n",
    "    faulty = cycle.copy()\n",
    "    T = faulty.shape[0]\n",
    "    center = T // 2\n",
    "\n",
    "    base_width = 80\n",
    "    width = int(base_width * (1.2 - 0.7 * severity))  # narrower for high severity\n",
    "    drop_psi = _interp_from_severity(severity, *cfg.vacuum_drop_range)\n",
    "\n",
    "    idx = np.arange(T)\n",
    "    dist2 = (idx - center) ** 2\n",
    "    sigma2 = (width / 3.0) ** 2\n",
    "    pulse = drop_psi * np.exp(-dist2 / (2.0 * sigma2))\n",
    "\n",
    "    P = faulty[:, 2]\n",
    "    P_faulty = np.clip(P - pulse, cfg.P_min, cfg.P_max)\n",
    "    faulty[:, 2] = P_faulty\n",
    "    return faulty\n",
    "\n",
    "\n",
    "def inject_cdra_degradation(cycle: np.ndarray, cfg: DatasetConfig,\n",
    "                            rng: np.random.Generator, severity: float) -> np.ndarray:\n",
    "    \"\"\"CDRA degradation: whole-cycle CO₂ baseline elevated.\"\"\"\n",
    "    faulty = cycle.copy()\n",
    "    offset = _interp_from_severity(severity, *cfg.cdra_offset_range)\n",
    "    faulty[:, 1] += offset\n",
    "    faulty[:, 1] = np.clip(faulty[:, 1], cfg.CO2_min, cfg.CO2_max)\n",
    "    return faulty\n",
    "\n",
    "\n",
    "def inject_oga_degradation(cycle: np.ndarray, cfg: DatasetConfig,\n",
    "                           rng: np.random.Generator, severity: float) -> np.ndarray:\n",
    "    \"\"\"OGA degradation: whole-cycle O₂ baseline reduced.\"\"\"\n",
    "    faulty = cycle.copy()\n",
    "    reduction = _interp_from_severity(severity, *cfg.oga_offset_range)\n",
    "    faulty[:, 0] -= reduction\n",
    "    faulty[:, 0] = np.clip(faulty[:, 0], cfg.O2_min, cfg.O2_max)\n",
    "    return faulty\n",
    "\n",
    "\n",
    "def apply_system_fault(system_class_id: int, cycle: np.ndarray,\n",
    "                       cfg: DatasetConfig, rng: np.random.Generator,\n",
    "                       severity: float) -> np.ndarray:\n",
    "    \"\"\"Dispatch to system fault injector based on class id.\"\"\"\n",
    "    if system_class_id == 0:\n",
    "        return cycle  # Nominal\n",
    "    elif system_class_id == 1:\n",
    "        return inject_co2_leak(cycle, cfg, rng, severity)\n",
    "    elif system_class_id == 2:\n",
    "        return inject_valve_stiction(cycle, cfg, rng, severity)\n",
    "    elif system_class_id == 3:\n",
    "        return inject_vacuum_anomaly(cycle, cfg, rng, severity)\n",
    "    elif system_class_id == 4:\n",
    "        return inject_cdra_degradation(cycle, cfg, rng, severity)\n",
    "    elif system_class_id == 5:\n",
    "        return inject_oga_degradation(cycle, cfg, rng, severity)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown system_class_id: {system_class_id}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# SENSOR FAULT MODELS\n",
    "# ============================================================\n",
    "\n",
    "def apply_sensor_bias_drift(cycle: np.ndarray, cfg: DatasetConfig,\n",
    "                            rng: np.random.Generator) -> np.ndarray:\n",
    "    \"\"\"Slow additive drift over the cycle for one random sensor channel.\"\"\"\n",
    "    faulty = cycle.copy()\n",
    "    T = faulty.shape[0]\n",
    "    ch = rng.integers(0, 3)\n",
    "\n",
    "    end_drift = rng.uniform(-cfg.bias_drift_max, cfg.bias_drift_max)\n",
    "    drift = np.linspace(0.0, end_drift, T)\n",
    "    faulty[:, ch] += drift\n",
    "    return faulty\n",
    "\n",
    "\n",
    "def apply_sensor_high_noise(cycle: np.ndarray, cfg: DatasetConfig,\n",
    "                            rng: np.random.Generator) -> np.ndarray:\n",
    "    \"\"\"Increase noise for some channels.\"\"\"\n",
    "    faulty = cycle.copy()\n",
    "    T = faulty.shape[0]\n",
    "\n",
    "    n_ch = rng.integers(1, 4)\n",
    "    channels = rng.choice([0, 1, 2], size=n_ch, replace=False)\n",
    "\n",
    "    noise_scales = {\n",
    "        0: cfg.O2_noise_std,\n",
    "        1: cfg.CO2_noise_std,\n",
    "        2: cfg.P_noise_std,\n",
    "    }\n",
    "\n",
    "    for ch in channels:\n",
    "        std = noise_scales[ch] * cfg.high_noise_factor\n",
    "        faulty[:, ch] += rng.normal(0.0, std, T)\n",
    "    return faulty\n",
    "\n",
    "\n",
    "def apply_sensor_partial_freeze(cycle: np.ndarray, cfg: DatasetConfig,\n",
    "                                rng: np.random.Generator) -> np.ndarray:\n",
    "    \"\"\"Segment of the time series where the sensor output freezes.\"\"\"\n",
    "    faulty = cycle.copy()\n",
    "    T = faulty.shape[0]\n",
    "    ch = rng.integers(0, 3)\n",
    "\n",
    "    frac_len = rng.uniform(cfg.freeze_min_fraction, cfg.freeze_max_fraction)\n",
    "    seg_len = int(T * frac_len)\n",
    "    if seg_len <= 1:\n",
    "        return faulty\n",
    "\n",
    "    start = rng.integers(0, T - seg_len)\n",
    "    end = start + seg_len\n",
    "\n",
    "    frozen_value = faulty[start, ch]\n",
    "    faulty[start:end, ch] = frozen_value\n",
    "    return faulty\n",
    "\n",
    "\n",
    "def apply_sensor_spike_outliers(cycle: np.ndarray, cfg: DatasetConfig,\n",
    "                                rng: np.random.Generator) -> np.ndarray:\n",
    "    \"\"\"Random spike outliers on a random channel.\"\"\"\n",
    "    faulty = cycle.copy()\n",
    "    T = faulty.shape[0]\n",
    "    ch = rng.integers(0, 3)\n",
    "\n",
    "    n_spikes = rng.integers(cfg.n_spikes_min, cfg.n_spikes_max + 1)\n",
    "    indices = rng.integers(0, T, size=n_spikes)\n",
    "\n",
    "    sign = rng.choice([-1.0, 1.0], size=n_spikes)\n",
    "    mag = rng.uniform(cfg.spike_magnitude_range[0],\n",
    "                      cfg.spike_magnitude_range[1],\n",
    "                      size=n_spikes)\n",
    "    faulty[indices, ch] += sign * mag\n",
    "    return faulty\n",
    "\n",
    "\n",
    "def apply_random_sensor_fault(cycle: np.ndarray, cfg: DatasetConfig,\n",
    "                              rng: np.random.Generator) -> Tuple[np.ndarray, int, str]:\n",
    "    \"\"\"Randomly choose a sensor fault type (excluding None) and apply.\"\"\"\n",
    "    fault_id, fault_name = SENSOR_FAULTS[rng.integers(1, len(SENSOR_FAULTS))]\n",
    "\n",
    "    if fault_id == 1:\n",
    "        new_cycle = apply_sensor_bias_drift(cycle, cfg, rng)\n",
    "    elif fault_id == 2:\n",
    "        new_cycle = apply_sensor_high_noise(cycle, cfg, rng)\n",
    "    elif fault_id == 3:\n",
    "        new_cycle = apply_sensor_partial_freeze(cycle, cfg, rng)\n",
    "    elif fault_id == 4:\n",
    "        new_cycle = apply_sensor_spike_outliers(cycle, cfg, rng)\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected sensor fault id: {fault_id}\")\n",
    "\n",
    "    return new_cycle, fault_id, fault_name\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# SAFETY FLAGS\n",
    "# ============================================================\n",
    "\n",
    "def compute_safety_flags(cycle: np.ndarray, cfg: DatasetConfig) -> Dict[str, bool]:\n",
    "    \"\"\"Compute simple NASA-inspired safety flags on a cycle.\"\"\"\n",
    "    O2 = cycle[:, 0]\n",
    "    CO2 = cycle[:, 1]\n",
    "    P = cycle[:, 2]\n",
    "\n",
    "    mean_O2 = float(O2.mean())\n",
    "    max_CO2 = float(CO2.max())\n",
    "    mean_P = float(P.mean())\n",
    "\n",
    "    return {\n",
    "        \"flag_CO2_warn\": max_CO2 > cfg.CO2_warn,\n",
    "        \"flag_CO2_crit\": max_CO2 > cfg.CO2_crit,\n",
    "        \"flag_O2_warn_low\": mean_O2 < cfg.O2_warn_low,\n",
    "        \"flag_O2_crit_low\": mean_O2 < cfg.O2_crit_low,\n",
    "        \"flag_P_warn\": not (cfg.P_warn_low <= mean_P <= cfg.P_warn_high),\n",
    "        \"flag_P_crit\": not (cfg.P_crit_low <= mean_P <= cfg.P_crit_high),\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# DATASET GENERATION\n",
    "# ============================================================\n",
    "\n",
    "def generate_dataset(cfg: DatasetConfig,\n",
    "                     out_dir: str | Path = DEFAULT_DATA_DIR\n",
    "                    ) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Generate full dataset with:\n",
    "      - 6 system classes\n",
    "      - 5 sensor fault types\n",
    "      - progressive severity per mode\n",
    "      - safety flags\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(cfg.random_seed)\n",
    "    out_path = Path(out_dir)\n",
    "    out_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    all_cycles: List[np.ndarray] = []\n",
    "    system_labels: List[int] = []\n",
    "    sensor_labels: List[int] = []\n",
    "    meta_rows: List[Dict] = []\n",
    "\n",
    "    sample_id = 0\n",
    "\n",
    "    for class_id, class_name in SYSTEM_CLASSES:\n",
    "        n = cfg.n_samples_per_system_class\n",
    "\n",
    "        for k in range(n):\n",
    "            # Severity: linearly increasing with some noise\n",
    "            base_frac = (k + 0.5) / n\n",
    "            severity = float(np.clip(base_frac + rng.normal(0.0, 0.1), 0.0, 1.0))\n",
    "\n",
    "            cycle_nominal = generate_nominal_cycle(cfg, rng)\n",
    "            cycle_sys = apply_system_fault(class_id, cycle_nominal, cfg, rng, severity)\n",
    "\n",
    "            # Sensor fault?\n",
    "            if cfg.enable_sensor_faults and rng.random() < cfg.p_sensor_fault:\n",
    "                cycle_faulty, sensor_fault_id, sensor_fault_name = apply_random_sensor_fault(\n",
    "                    cycle_sys, cfg, rng\n",
    "                )\n",
    "            else:\n",
    "                cycle_faulty = cycle_sys\n",
    "                sensor_fault_id, sensor_fault_name = SENSOR_FAULTS[0]\n",
    "\n",
    "            # Enforce physical sensor range after sensor faults\n",
    "            cycle_final = cycle_faulty.copy()\n",
    "            cycle_final[:, 0] = np.clip(cycle_final[:, 0], cfg.O2_min, cfg.O2_max)\n",
    "            cycle_final[:, 1] = np.clip(cycle_final[:, 1], cfg.CO2_min, cfg.CO2_max)\n",
    "            cycle_final[:, 2] = np.clip(cycle_final[:, 2], cfg.P_min, cfg.P_max)\n",
    "\n",
    "            flags = compute_safety_flags(cycle_final, cfg)\n",
    "\n",
    "\n",
    "            all_cycles.append(cycle_final)\n",
    "            system_labels.append(class_id)\n",
    "            sensor_labels.append(sensor_fault_id)\n",
    "\n",
    "            row = {\n",
    "                \"sample_id\": sample_id,\n",
    "                \"system_class_id\": class_id,\n",
    "                \"system_class_name\": class_name,\n",
    "                \"sensor_fault_id\": sensor_fault_id,\n",
    "                \"sensor_fault_name\": sensor_fault_name,\n",
    "                \"severity\": severity,\n",
    "                \"replicate_idx\": k,\n",
    "            }\n",
    "            row.update(flags)\n",
    "            meta_rows.append(row)\n",
    "\n",
    "            sample_id += 1\n",
    "\n",
    "    data_3d = np.stack(all_cycles, axis=0)             # (N, T, 3)\n",
    "    labels_system = np.array(system_labels, dtype=int)\n",
    "    labels_sensor = np.array(sensor_labels, dtype=int)\n",
    "    data_flat = data_3d.reshape(data_3d.shape[0], -1)  # (N, 3T)\n",
    "\n",
    "    # Quick sanity prints\n",
    "    print(\"=== BASIC VALIDATION (quick) ===\")\n",
    "    print(\"Shape (N, T, C):\", data_3d.shape)\n",
    "    print(\"System class counts:\", np.bincount(labels_system))\n",
    "    print(\"Sensor fault counts:\", np.bincount(labels_sensor))\n",
    "\n",
    "    O2 = data_3d[:, :, 0]\n",
    "    CO2 = data_3d[:, :, 1]\n",
    "    P = data_3d[:, :, 2]\n",
    "\n",
    "    print(\"O2 in [0,100]:\", bool(np.all((O2 >= cfg.O2_min) & (O2 <= cfg.O2_max))))\n",
    "    print(\"CO2 in [0,5]:  \", bool(np.all((CO2 >= cfg.CO2_min) & (CO2 <= cfg.CO2_max))))\n",
    "    print(\"P in [0,20]:   \", bool(np.all((P >= cfg.P_min) & (P <= cfg.P_max))))\n",
    "\n",
    "    df_meta = pd.DataFrame(meta_rows)\n",
    "    for class_id, class_name in SYSTEM_CLASSES:\n",
    "        idx = np.where(labels_system == class_id)[0]\n",
    "        O2_c = O2[idx].mean()\n",
    "        CO2_c = CO2[idx].mean()\n",
    "        P_c = P[idx].mean()\n",
    "        print(f\"Class {class_id} ({class_name}): \"\n",
    "              f\"mean O2={O2_c:.3f}, CO2={CO2_c:.3f}, P={P_c:.3f}\")\n",
    "\n",
    "    # Save arrays + metadata\n",
    "    np.save(out_path / \"cycles_3d.npy\", data_3d)\n",
    "    np.save(out_path / \"cycles_flat.npy\", data_flat)\n",
    "    np.save(out_path / \"labels_system.npy\", labels_system)\n",
    "    np.save(out_path / \"labels_sensor.npy\", labels_sensor)\n",
    "\n",
    "    df_meta.to_csv(out_path / \"metadata.csv\", index=False)\n",
    "    with open(out_path / \"config.json\", \"w\") as f:\n",
    "        json.dump(asdict(cfg), f, indent=2)\n",
    "\n",
    "    print(f\"\\nSaved dataset to: {out_path.resolve()}\")\n",
    "\n",
    "    return {\n",
    "        \"data_3d\": data_3d,\n",
    "        \"data_flat\": data_flat,\n",
    "        \"labels_system\": labels_system,\n",
    "        \"labels_sensor\": labels_sensor,\n",
    "        \"metadata\": df_meta,\n",
    "        \"out_dir\": out_dir,\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# COMPREHENSIVE VALIDATION\n",
    "# ============================================================\n",
    "\n",
    "def validate_dataset(data_3d: np.ndarray,\n",
    "                     labels_system: np.ndarray,\n",
    "                     cfg: DatasetConfig) -> bool:\n",
    "    \"\"\"\n",
    "    Comprehensive validation:\n",
    "      - Physical constraints\n",
    "      - NaN / Inf\n",
    "      - Temporal coherence (lag-1 autocorr)\n",
    "      - Optional class separability (PCA + silhouette, if sklearn available)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"COMPREHENSIVE VALIDATION\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    all_pass = True\n",
    "\n",
    "    O2 = data_3d[:, :, 0]\n",
    "    CO2 = data_3d[:, :, 1]\n",
    "    P = data_3d[:, :, 2]\n",
    "\n",
    "    # 1. Physical constraints\n",
    "    O2_valid = np.all((O2 >= cfg.O2_min) & (O2 <= cfg.O2_max))\n",
    "    CO2_valid = np.all((CO2 >= cfg.CO2_min) & (CO2 <= cfg.CO2_max))\n",
    "    P_valid = np.all((P >= cfg.P_min) & (P <= cfg.P_max))\n",
    "\n",
    "    print(\"\\n1. Physical Constraints:\")\n",
    "    print(f\"   O2 in [{cfg.O2_min}, {cfg.O2_max}]: {'✅' if O2_valid else '❌'}\")\n",
    "    print(f\"   CO2 in [{cfg.CO2_min}, {cfg.CO2_max}]: {'✅' if CO2_valid else '❌'}\")\n",
    "    print(f\"   P in [{cfg.P_min}, {cfg.P_max}]:   {'✅' if P_valid else '❌'}\")\n",
    "\n",
    "    all_pass &= (O2_valid and CO2_valid and P_valid)\n",
    "\n",
    "    # 2. NaN / Inf\n",
    "    has_nan = np.isnan(data_3d).any()\n",
    "    has_inf = np.isinf(data_3d).any()\n",
    "\n",
    "    print(\"\\n2. Invalid Values:\")\n",
    "    print(f\"   No NaN: {'✅' if not has_nan else '❌'}\")\n",
    "    print(f\"   No Inf: {'✅' if not has_inf else '❌'}\")\n",
    "\n",
    "    all_pass &= (not has_nan and not has_inf)\n",
    "\n",
    "    # 3. Temporal coherence via lag-1 autocorrelation\n",
    "    print(\"\\n3. Temporal Coherence:\")\n",
    "    autocorrs = []\n",
    "    n_samples = min(20, len(data_3d))\n",
    "    for i in range(n_samples):\n",
    "        for sensor_idx in range(3):\n",
    "            signal = data_3d[i, :, sensor_idx]\n",
    "            if signal.std() > 0:\n",
    "                x = signal[:-1]\n",
    "                y = signal[1:]\n",
    "                cov = np.cov(x, y)[0, 1]\n",
    "                denom = np.std(x) * np.std(y)\n",
    "                if denom > 0:\n",
    "                    acf = cov / denom\n",
    "                    autocorrs.append(acf)\n",
    "\n",
    "    if autocorrs:\n",
    "        mean_acf = float(np.mean(autocorrs))\n",
    "        temporal_ok = mean_acf > 0.7\n",
    "        print(f\"   Mean lag-1 autocorr: {mean_acf:.3f} \"\n",
    "              f\"{'✅' if temporal_ok else '⚠️'}\")\n",
    "    else:\n",
    "        temporal_ok = False\n",
    "        print(\"   Could not compute autocorrelation (degenerate signals) ⚠️\")\n",
    "\n",
    "    # 4. Class separability (optional, requires sklearn)\n",
    "    print(\"\\n4. Class Separability (PCA + silhouette):\")\n",
    "    try:\n",
    "        from sklearn.decomposition import PCA\n",
    "        from sklearn.metrics import silhouette_score\n",
    "\n",
    "        data_flat = data_3d.reshape(len(data_3d), -1)\n",
    "        pca = PCA(n_components=2)\n",
    "        data_2d = pca.fit_transform(data_flat)\n",
    "        sil_score = float(silhouette_score(data_2d, labels_system))\n",
    "        separable = sil_score > 0.2\n",
    "        print(f\"   Silhouette score (2D PCA): {sil_score:.3f} \"\n",
    "              f\"{'✅' if separable else '⚠️'}\")\n",
    "    except ImportError:\n",
    "        print(\"   sklearn not available → skipping separability check (OK).\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"OVERALL PHYSICAL/NUMERIC: {'✅ PASS' if all_pass else '❌ FAIL'}\")\n",
    "    print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "    return all_pass\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# VISUAL VALIDATION (OVERLAY PLOTS)\n",
    "# ============================================================\n",
    "\n",
    "def visualize_samples(data_3d: np.ndarray,\n",
    "                      labels_system: np.ndarray,\n",
    "                      out_dir: str = \"eclss_synthetic_dataset_full\") -> None:\n",
    "    \"\"\"Generate overlay plots (O2, CO2, P) for each system class.\"\"\"\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "    except ImportError:\n",
    "        print(\"Matplotlib not available, skipping visualization.\")\n",
    "        return\n",
    "\n",
    "    out_path = Path(out_dir)\n",
    "    out_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    n_classes = len(SYSTEM_CLASSES)\n",
    "    sensor_names = ['O2 (%)', 'CO2 (%)', 'Pressure (psi)']\n",
    "\n",
    "    fig, axes = plt.subplots(n_classes, 3, figsize=(15, 2.8 * n_classes), sharex=True)\n",
    "    if n_classes == 1:\n",
    "        axes = np.expand_dims(axes, axis=0)  # ensure 2D\n",
    "\n",
    "    for row_idx, (class_id, class_name) in enumerate(SYSTEM_CLASSES):\n",
    "        class_data = data_3d[labels_system == class_id]\n",
    "        if class_data.size == 0:\n",
    "            continue\n",
    "\n",
    "        for sensor_idx, sensor_name in enumerate(sensor_names):\n",
    "            ax = axes[row_idx, sensor_idx]\n",
    "\n",
    "            n_plot = min(10, len(class_data))\n",
    "            for sample in class_data[:n_plot]:\n",
    "                ax.plot(sample[:, sensor_idx], alpha=0.3, linewidth=0.8)\n",
    "\n",
    "            mean_signal = class_data[:, :, sensor_idx].mean(axis=0)\n",
    "            ax.plot(mean_signal, 'k-', linewidth=2.0, label='Mean')\n",
    "\n",
    "            if sensor_idx == 0:\n",
    "                ax.set_ylabel(class_name, fontsize=10, fontweight='bold')\n",
    "            if row_idx == 0:\n",
    "                ax.set_title(sensor_name, fontsize=11, fontweight='bold')\n",
    "            if row_idx == n_classes - 1:\n",
    "                ax.set_xlabel('Timestep', fontsize=9)\n",
    "\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.legend(fontsize=7, loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig_file = out_path / \"dataset_validation_overlay.png\"\n",
    "    plt.savefig(fig_file, dpi=150, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"✅ Visual validation saved: {fig_file}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# SUMMARY REPORT\n",
    "# ============================================================\n",
    "\n",
    "def generate_summary_report(data_3d: np.ndarray,\n",
    "                            labels_system: np.ndarray,\n",
    "                            labels_sensor: np.ndarray,\n",
    "                            df_meta: pd.DataFrame,\n",
    "                            cfg: DatasetConfig,\n",
    "                            out_dir: str) -> None:\n",
    "    \"\"\"Generate a human-readable markdown summary report.\"\"\"\n",
    "    out_path = Path(out_dir)\n",
    "    out_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    O2 = data_3d[:, :, 0]\n",
    "    CO2 = data_3d[:, :, 1]\n",
    "    P = data_3d[:, :, 2]\n",
    "\n",
    "    report = f\"\"\"# ECLSS Synthetic Dataset Summary\n",
    "\n",
    "## Dataset Statistics\n",
    "\n",
    "- Total Samples: {len(data_3d)}\n",
    "- Timesteps per Sample: {cfg.n_timesteps}\n",
    "- Sensors: 3 (O₂, CO₂, Pressure)\n",
    "- Sampling Rate: {cfg.sampling_rate_hz} Hz\n",
    "- Cycle Duration: {cfg.n_timesteps / cfg.sampling_rate_hz / 60:.1f} minutes\n",
    "\n",
    "## System Class Distribution\n",
    "\n",
    "| Class ID | Class Name | Count | Percentage |\n",
    "|----------|------------|-------|------------|\n",
    "\"\"\"\n",
    "    for class_id, class_name in SYSTEM_CLASSES:\n",
    "        count = int((labels_system == class_id).sum())\n",
    "        pct = count / len(labels_system) * 100\n",
    "        report += f\"| {class_id} | {class_name} | {count} | {pct:.1f}% |\\n\"\n",
    "\n",
    "    report += \"\\n## Sensor Fault Distribution\\n\\n\"\n",
    "    report += \"| Fault ID | Fault Name | Count | Percentage |\\n\"\n",
    "    report += \"|----------|------------|-------|------------|\\n\"\n",
    "\n",
    "    for fault_id, fault_name in SENSOR_FAULTS:\n",
    "        count = int((labels_sensor == fault_id).sum())\n",
    "        pct = count / len(labels_sensor) * 100\n",
    "        report += f\"| {fault_id} | {fault_name} | {count} | {pct:.1f}% |\\n\"\n",
    "\n",
    "    # Safety flags summary\n",
    "    report += \"\\n## Safety Flags Triggered\\n\\n\"\n",
    "    for col in df_meta.columns:\n",
    "        if col.startswith(\"flag_\"):\n",
    "            count = int(df_meta[col].sum())\n",
    "            pct = count / len(df_meta) * 100\n",
    "            report += f\"- {col}: {count} samples ({pct:.1f}%)\\n\"\n",
    "\n",
    "    # Sensor statistics\n",
    "    report += f\"\"\"\n",
    "\n",
    "## Sensor Value Ranges\n",
    "\n",
    "| Sensor | Min | Max | Mean | Std |\n",
    "|--------|-----|-----|------|-----|\n",
    "| O₂ (%) | {O2.min():.3f} | {O2.max():.3f} | {O2.mean():.3f} | {O2.std():.3f} |\n",
    "| CO₂ (%) | {CO2.min():.3f} | {CO2.max():.3f} | {CO2.mean():.3f} | {CO2.std():.3f} |\n",
    "| Pressure (psi) | {P.min():.3f} | {P.max():.3f} | {P.mean():.3f} | {P.std():.3f} |\n",
    "\n",
    "## Configuration (JSON)\n",
    "\n",
    "{json.dumps(asdict(cfg), indent=2)}\n",
    "\n",
    "---\n",
    "\n",
    "*Generated on {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}*\n",
    "\"\"\"\n",
    "    # ============================================================\n",
    "    # Write summary file\n",
    "    # ============================================================\n",
    "    summary_file = out_path / \"dataset_summary.md\"\n",
    "    with open(summary_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(report)\n",
    "\n",
    "    print(f\"✅ Summary report saved: {summary_file}\")\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = DatasetConfig(\n",
    "        n_samples_per_system_class=30,\n",
    "        n_timesteps=1000,\n",
    "        sampling_rate_hz=2.0,\n",
    "    )\n",
    "\n",
    "    out = generate_dataset(cfg)\n",
    "    passed = validate_dataset(out[\"data_3d\"], out[\"labels_system\"], cfg)\n",
    "\n",
    "    if passed:\n",
    "        visualize_samples(out[\"data_3d\"], out[\"labels_system\"], out[\"out_dir\"])\n",
    "        generate_summary_report(\n",
    "            out[\"data_3d\"],\n",
    "            out[\"labels_system\"],\n",
    "            out[\"labels_sensor\"],\n",
    "            out[\"metadata\"],\n",
    "            cfg,\n",
    "            out[\"out_dir\"],\n",
    "        )\n",
    "        print(\"\\n✅ Dataset generation, validation, plots, and summary complete.\")\n",
    "        print(\"   Ready for VAE/SVM training.\")\n",
    "    else:\n",
    "        print(\"\\n❌ Validation failed. Please inspect logs before training.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8659a56b-e5d6-4660-9162-38ebabddce3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
