{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4db94b36-3ff5-4f01-a930-dcfc49b443b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      " PREPROCESSING ECLSS SYNTHETIC DATASET\n",
      "============================================================\n",
      "Raw data directory: C:\\Users\\ahasa\\project_root\\data\\eclss_synthetic_dataset_full\n",
      "Output directory:   C:\\Users\\ahasa\\project_root\\data\\eclss_preprocessed\n",
      "\n",
      "Total samples: 720\n",
      "  Nominal (class 0): 120\n",
      "  Faulty  (class 1–5): 600\n",
      "\n",
      "Separated data:\n",
      "  Nominal samples: 120\n",
      "  Faulty samples:  600\n",
      "\n",
      "Nominal split (for VAE):\n",
      "  Train: 84\n",
      "  Val:   18\n",
      "  Test:  18\n",
      "\n",
      "Faulty split (for SVM and evaluation):\n",
      "  Train (faulty): 420\n",
      "  Test  (faulty): 180\n",
      "  Fault distribution (train): [ 0 84 84 84 84 84]\n",
      "  Fault distribution (test):  [ 0 36 36 36 36 36]\n",
      "\n",
      "Combined test set (for VAE anomaly detection):\n",
      "  Total:   198\n",
      "  Nominal: 18\n",
      "  Anomaly: 180\n",
      "\n",
      "Scaler fitted on NOMINAL training data only:\n",
      "  Means: [20.90136217  0.30160151 14.70007224]\n",
      "  Stds:  [0.22969965 0.0816969  0.2204265 ]\n",
      "\n",
      "Saving preprocessed data to disk...\n",
      "\n",
      "✅ Saved all preprocessed data to: C:\\Users\\ahasa\\project_root\\data\\eclss_preprocessed\n",
      "============================================================\n",
      " PREPROCESSING COMPLETE\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "preprocess_eclss.py\n",
    "\n",
    "Preprocessing pipeline for the ECLSS synthetic dataset.\n",
    "\n",
    "- Loads raw data from: data/eclss_synthetic_dataset_full/\n",
    "    - cycles_3d.npy        (N, T, 3)\n",
    "    - labels_system.npy    (N,)\n",
    "    - labels_sensor.npy    (N,)\n",
    "\n",
    "- Splits data into:\n",
    "    * Nominal (class 0) → for VAE:\n",
    "        - X_train_nom_*  (train)\n",
    "        - X_val_nom_*    (validation)\n",
    "        - X_test_nom_*   (part of combined test set)\n",
    "    * Faulty (classes 1–5) → for SVM and anomaly evaluation:\n",
    "        - X_train_fault_*      (SVM train)\n",
    "        - X_test_fault_*       (SVM test)\n",
    "        - X_test_all_*         (VAE anomaly test: nominal + faulty)\n",
    "\n",
    "- Normalizes using StandardScaler fitted ONLY on nominal training data.\n",
    "\n",
    "- Saves preprocessed arrays under:\n",
    "    data/eclss_preprocessed/\n",
    "\n",
    "This script is safe to run:\n",
    "  * as a standalone .py in a repo (uses REPO_ROOT/data/…)\n",
    "  * inside a Jupyter/Colab notebook (falls back to current working directory).\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# PATH CONFIGURATION\n",
    "# ============================================================\n",
    "\n",
    "# If running as a script, __file__ is defined.\n",
    "# If running inside a notebook, fall back to current working directory.\n",
    "try:\n",
    "    REPO_ROOT = Path(__file__).resolve().parents[1]\n",
    "except NameError:\n",
    "    REPO_ROOT = Path.cwd()\n",
    "\n",
    "DATA_ROOT = REPO_ROOT / \"data\"\n",
    "\n",
    "RAW_DIR = DATA_ROOT / \"eclss_synthetic_dataset_full\"\n",
    "OUT_DIR = DATA_ROOT / \"eclss_preprocessed\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CYCLES_FILE = RAW_DIR / \"cycles_3d.npy\"\n",
    "SYS_LABELS_FILE = RAW_DIR / \"labels_system.npy\"\n",
    "SENSOR_LABELS_FILE = RAW_DIR / \"labels_sensor.npy\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# HELPER: SCALE 3D ARRAY\n",
    "# ============================================================\n",
    "\n",
    "def scale_3d(X: np.ndarray, scaler: StandardScaler) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Scale a 3D array (N, T, C) using a fitted StandardScaler\n",
    "    (which expects 2D input of shape (N*T, C)).\n",
    "\n",
    "    Returns (N, T, C) scaled.\n",
    "    \"\"\"\n",
    "    N, T, C = X.shape\n",
    "    X_2d = X.reshape(-1, C)          # (N*T, C)\n",
    "    X_scaled_2d = scaler.transform(X_2d)\n",
    "    return X_scaled_2d.reshape(N, T, C)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN PREPROCESSING PIPELINE\n",
    "# ============================================================\n",
    "\n",
    "def main() -> None:\n",
    "    print(\"============================================================\")\n",
    "    print(\" PREPROCESSING ECLSS SYNTHETIC DATASET\")\n",
    "    print(\"============================================================\")\n",
    "\n",
    "    print(f\"Raw data directory: {RAW_DIR}\")\n",
    "    print(f\"Output directory:   {OUT_DIR}\\n\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 1) LOAD RAW DATA\n",
    "    # --------------------------------------------------------\n",
    "    X = np.load(CYCLES_FILE)           # (N, T, 3)\n",
    "    y_sys = np.load(SYS_LABELS_FILE)   # (N,)\n",
    "    y_sensor = np.load(SENSOR_LABELS_FILE)  # (N,)\n",
    "\n",
    "    print(f\"Total samples: {len(X)}\")\n",
    "    print(f\"  Nominal (class 0): {(y_sys == 0).sum()}\")\n",
    "    print(f\"  Faulty  (class 1–5): {(y_sys > 0).sum()}\\n\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 2) SEPARATE NOMINAL AND FAULTY\n",
    "    # --------------------------------------------------------\n",
    "    nom_mask = (y_sys == 0)\n",
    "    fault_mask = (y_sys > 0)\n",
    "\n",
    "    X_nom = X[nom_mask]\n",
    "    y_sys_nom = y_sys[nom_mask]\n",
    "    y_sensor_nom = y_sensor[nom_mask]\n",
    "\n",
    "    X_fault = X[fault_mask]\n",
    "    y_sys_fault = y_sys[fault_mask]\n",
    "    y_sensor_fault = y_sensor[fault_mask]\n",
    "\n",
    "    print(\"Separated data:\")\n",
    "    print(f\"  Nominal samples: {len(X_nom)}\")\n",
    "    print(f\"  Faulty samples:  {len(X_fault)}\\n\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 3) SPLIT NOMINAL DATA FOR VAE\n",
    "    #    70% train, 15% val, 15% test\n",
    "    # --------------------------------------------------------\n",
    "    X_nom_train, X_nom_temp, y_sys_nom_train, y_sys_nom_temp = train_test_split(\n",
    "        X_nom, y_sys_nom, test_size=0.30, random_state=42\n",
    "    )\n",
    "\n",
    "    X_nom_val, X_nom_test, y_sys_nom_val, y_sys_nom_test = train_test_split(\n",
    "        X_nom_temp, y_sys_nom_temp, test_size=0.50, random_state=42\n",
    "    )\n",
    "\n",
    "    print(\"Nominal split (for VAE):\")\n",
    "    print(f\"  Train: {len(X_nom_train)}\")\n",
    "    print(f\"  Val:   {len(X_nom_val)}\")\n",
    "    print(f\"  Test:  {len(X_nom_test)}\\n\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 4) SPLIT FAULTY DATA FOR SVM + ANOMALY TEST\n",
    "    #    70% train, 30% test – stratified by system fault type\n",
    "    # --------------------------------------------------------\n",
    "    (X_fault_train,\n",
    "     X_fault_test,\n",
    "     y_sys_fault_train,\n",
    "     y_sys_fault_test,\n",
    "     y_sensor_fault_train,\n",
    "     y_sensor_fault_test) = train_test_split(\n",
    "        X_fault,\n",
    "        y_sys_fault,\n",
    "        y_sensor_fault,\n",
    "        test_size=0.30,\n",
    "        stratify=y_sys_fault,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    print(\"Faulty split (for SVM and evaluation):\")\n",
    "    print(f\"  Train (faulty): {len(X_fault_train)}\")\n",
    "    print(f\"  Test  (faulty): {len(X_fault_test)}\")\n",
    "    print(\"  Fault distribution (train):\", np.bincount(y_sys_fault_train))\n",
    "    print(\"  Fault distribution (test): \", np.bincount(y_sys_fault_test))\n",
    "    print()\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 5) COMBINED TEST SET FOR ANOMALY DETECTION\n",
    "    #    (nominal test + faulty test)\n",
    "    # --------------------------------------------------------\n",
    "    X_test_all = np.concatenate([X_nom_test, X_fault_test], axis=0)\n",
    "    y_sys_test_all = np.concatenate([y_sys_nom_test, y_sys_fault_test])\n",
    "    y_binary_test_all = (y_sys_test_all > 0).astype(int)  # 0=nominal, 1=anomaly\n",
    "\n",
    "    print(\"Combined test set (for VAE anomaly detection):\")\n",
    "    print(f\"  Total:   {len(X_test_all)}\")\n",
    "    print(f\"  Nominal: {(y_binary_test_all == 0).sum()}\")\n",
    "    print(f\"  Anomaly: {(y_binary_test_all == 1).sum()}\\n\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 6) NORMALIZATION (FIT SCALER ON NOMINAL TRAIN ONLY)\n",
    "    # --------------------------------------------------------\n",
    "    N_nom_train, T, C = X_nom_train.shape\n",
    "    X_nom_train_2d = X_nom_train.reshape(-1, C)  # (N_nom_train*T, 3)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_nom_train_2d)\n",
    "\n",
    "    print(\"Scaler fitted on NOMINAL training data only:\")\n",
    "    print(f\"  Means: {scaler.mean_}\")\n",
    "    print(f\"  Stds:  {np.sqrt(scaler.var_)}\\n\")\n",
    "\n",
    "    # Scale all relevant splits\n",
    "    X_nom_train_scaled = scale_3d(X_nom_train, scaler)\n",
    "    X_nom_val_scaled = scale_3d(X_nom_val, scaler)\n",
    "    X_nom_test_scaled = scale_3d(X_nom_test, scaler)\n",
    "\n",
    "    X_fault_train_scaled = scale_3d(X_fault_train, scaler)\n",
    "    X_fault_test_scaled = scale_3d(X_fault_test, scaler)\n",
    "\n",
    "    X_test_all_scaled = scale_3d(X_test_all, scaler)\n",
    "\n",
    "    # Flattened versions (for MLP-based VAE / simple models)\n",
    "    X_nom_train_flat = X_nom_train_scaled.reshape(len(X_nom_train), -1)\n",
    "    X_nom_val_flat = X_nom_val_scaled.reshape(len(X_nom_val), -1)\n",
    "    X_nom_test_flat = X_nom_test_scaled.reshape(len(X_nom_test), -1)\n",
    "\n",
    "    X_fault_train_flat = X_fault_train_scaled.reshape(len(X_fault_train), -1)\n",
    "    X_fault_test_flat = X_fault_test_scaled.reshape(len(X_fault_test), -1)\n",
    "\n",
    "    X_test_all_flat = X_test_all_scaled.reshape(len(X_test_all), -1)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 7) SAVE ALL PREPROCESSED DATA\n",
    "    # --------------------------------------------------------\n",
    "    print(\"Saving preprocessed data to disk...\")\n",
    "\n",
    "    # --- VAE training data (nominal only) ---\n",
    "    np.save(OUT_DIR / \"X_train_nom_scaled.npy\", X_nom_train_scaled)\n",
    "    np.save(OUT_DIR / \"X_train_nom_flat.npy\", X_nom_train_flat)\n",
    "\n",
    "    np.save(OUT_DIR / \"X_val_nom_scaled.npy\", X_nom_val_scaled)\n",
    "    np.save(OUT_DIR / \"X_val_nom_flat.npy\", X_nom_val_flat)\n",
    "\n",
    "    np.save(OUT_DIR / \"X_test_nom_scaled.npy\", X_nom_test_scaled)\n",
    "    np.save(OUT_DIR / \"X_test_nom_flat.npy\", X_nom_test_flat)\n",
    "    np.save(OUT_DIR / \"y_test_nom_sys.npy\", y_sys_nom_test)\n",
    "\n",
    "    # --- SVM training data (faulty only) ---\n",
    "    np.save(OUT_DIR / \"X_train_fault_scaled.npy\", X_fault_train_scaled)\n",
    "    np.save(OUT_DIR / \"X_train_fault_flat.npy\", X_fault_train_flat)\n",
    "    np.save(OUT_DIR / \"y_train_fault_sys.npy\", y_sys_fault_train)\n",
    "    np.save(OUT_DIR / \"y_train_fault_sensor.npy\", y_sensor_fault_train)\n",
    "\n",
    "    # --- Combined test set for anomaly detection (nominal + faulty) ---\n",
    "    np.save(OUT_DIR / \"X_test_all_scaled.npy\", X_test_all_scaled)\n",
    "    np.save(OUT_DIR / \"X_test_all_flat.npy\", X_test_all_flat)\n",
    "    np.save(OUT_DIR / \"y_test_all_sys.npy\", y_sys_test_all)\n",
    "    np.save(OUT_DIR / \"y_test_all_binary.npy\", y_binary_test_all)\n",
    "\n",
    "    # --- Faulty test set for SVM evaluation ---\n",
    "    np.save(OUT_DIR / \"X_test_fault_scaled.npy\", X_fault_test_scaled)\n",
    "    np.save(OUT_DIR / \"X_test_fault_flat.npy\", X_fault_test_flat)\n",
    "    np.save(OUT_DIR / \"y_test_fault_sys.npy\", y_sys_fault_test)\n",
    "    np.save(OUT_DIR / \"y_test_fault_sensor.npy\", y_sensor_fault_test)\n",
    "\n",
    "    # --- Save scaler ---\n",
    "    joblib.dump(scaler, OUT_DIR / \"scaler.pkl\")\n",
    "\n",
    "    print(f\"\\n✅ Saved all preprocessed data to: {OUT_DIR.resolve()}\")\n",
    "    print(\"============================================================\")\n",
    "    print(\" PREPROCESSING COMPLETE\")\n",
    "    print(\"============================================================\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdffed24-f7d9-4d6f-80ea-15c681714544",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
